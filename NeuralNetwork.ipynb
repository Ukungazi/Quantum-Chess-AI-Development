{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e96370-5197-45fc-ac58-27da38284a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from QuantumChessGame import * \n",
    "from ChessPuzzles import *\n",
    "from GameToTensor import *\n",
    "from ChessPuzzles import chess_puzzles\n",
    "\n",
    "from MCTS import MCTS_Node\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import QChessNN\n",
    "import MCTS_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbdf535-9813-4617-8f75-e383008965ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#Declare a new model\n",
    "#NNmodel = QChessNN.QChessNN()\n",
    "\n",
    "\n",
    "\n",
    "# Load the model\n",
    "NNmodel = QChessNN.QChessNN()\n",
    "#NNmodel = torch.jit.load('testExport.pt')\n",
    "#NNmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c4fe3e-cab3-4570-83a7-8ed2d695c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import mathplotlib.pyplot as plt\n",
    "#%mathplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8d326e-8363-4450-9d14-6f957efb08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = QuantumChessGame()\n",
    "game.new_game()\n",
    "\n",
    "gameData = game.get_game_data()\n",
    "game_tensor = torch.zeros(1,12,8,8)\n",
    "\n",
    "game_tensor[0] = gameToTensor(gameData, 0)\n",
    "#print(game_tensor)\n",
    "y = torch.zeros(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe234e6-fdb4-4ee4-a159-6be73e6c9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS_AI:\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def find_best_move(self, game, simVar):\n",
    "        root = MCTS_Node(game)\n",
    "        gamedata = game.get_game_data()\n",
    "        bestmove = root.best_action(gamedata.ply, simVar)\n",
    "        return bestmove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c2a90a-da4d-407d-846d-e1ce8afc1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkMCTS():\n",
    "    def __init__(self):\n",
    "            return\n",
    "\n",
    "    \n",
    "    def find_best_move(self, game, model, simVar):\n",
    "        root = MCTS_NN.MCTS_Node(game, model)\n",
    "        gamedata = game.get_game_data()\n",
    "        bestmove, value = root.best_action(gamedata.ply, model, simVar)\n",
    "        return bestmove, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de584816-f491-4f59-a8e0-fed14b8fdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts_nn = NetworkMCTS()\n",
    "\n",
    "MCTSAI =  MCTS_AI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c60bc97f-46d4-4b91-903b-a3d4905db0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def self_play_game(model, moveMax, player1bot = True, player2bot = True):\n",
    "    board_data_B = []\n",
    "    board_data_W = []\n",
    "    values_B = []\n",
    "    values_W = []\n",
    "    moves_B = []\n",
    "    moves_W = []\n",
    "    game = QuantumChessGame()\n",
    "    game.new_game({'initial_state_fen':get_puzzle_fen(random.randint(33,35)),  'max_split_moves':[1,1]});\n",
    "    movecode = 0;\n",
    "    while not game.is_game_over():\n",
    "        gamedata = game.get_game_data()\n",
    "\n",
    "        board_data_W.append(gamedata)\n",
    "        values_W.append(0)\n",
    "        board_data_B.append(gamedata)\n",
    "        values_B.append(0)\n",
    "\n",
    "        #best_move, value = mcts_nn.find_best_move(game, model, 30)\n",
    "\n",
    "        #best_move = MCTSAI.find_best_move(game, 35)\n",
    "        \n",
    "        #print(f\"Value {value}\")\n",
    "        #print(\"found best move\")\n",
    "\n",
    "        \n",
    "        # Record the state, policy, and value\n",
    "        if (gamedata.ply % 2 == 0):\n",
    "            if(player1bot):\n",
    "                #best_move, value = MCTSAI.find_best_move(game, 50)\n",
    "                best_move, value = mcts_nn.find_best_move(game, model, 3)\n",
    "            else:\n",
    "                best_move = input(\"Enter your move: \")\n",
    "                value = 0\n",
    "            board_data_W.append(gamedata)\n",
    "            values_W.append(value)\n",
    "\n",
    "        if (gamedata.ply % 2 == 1):\n",
    "            if(player2bot):\n",
    "                #best_move, value = MCTSAI.find_best_move(game, 50)\n",
    "                best_move, value = mcts_nn.find_best_move(game, model, 3)\n",
    "            else:\n",
    "                best_move = input(\"Enter your move: \")\n",
    "                value = 0\n",
    "            board_data_B.append(gamedata)\n",
    "            values_B.append(value)\n",
    "        \n",
    "        \n",
    "\n",
    "        if (gamedata.ply == moveMax):\n",
    "            return board_data_W, board_data_B, moves_W, moves_B, values_W, values_B, 0\n",
    "        \n",
    "        print(f\"player # {gamedata.ply}\")\n",
    "        print(f\"move taken {best_move}\")\n",
    "        \n",
    "        # Apply the move to the board\n",
    "        board_state, movecode = game.do_move(best_move)\n",
    "        move = game.get_unformatted_last_move()\n",
    "        print(f\"move {move}\")\n",
    "        if (gamedata.ply % 2 == 1):\n",
    "            moves_W.append(move)\n",
    "        if (gamedata.ply % 2 == 0):\n",
    "            moves_B.append(move)\n",
    "            \n",
    "        game.print_board_and_probabilities()\n",
    "        \n",
    "    if(movecode == 2):\n",
    "        return board_data_W, board_data_B, moves_W, moves_B, values_W, values_B, 1  # Return +1 for  white win, 0 for draw, -1 for black win\n",
    "\n",
    "    if(movecode == 3):\n",
    "        return board_data_W, board_data_B, moves_W, moves_B, values_W, values_B, 0  # Return +1 for  white win, 0 for draw, -1 for black win\n",
    "\n",
    "    if(movecode == 5):\n",
    "        return board_data_W, board_data_B, moves_W, moves_B, values_W, values_B, -1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f1c985-06ca-46f7-8c39-d94b183dd3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch 1\n",
      "1 player # in model\n",
      "player # 1\n",
      "move taken a8^a7b8\n",
      "move {'piece': 14, 'square1': 56, 'square2': 48, 'square3': 57, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .    50:k   .     .     .     .     .     .   |\n",
      "7|  50:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .   100:N   .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "2 player # in model\n",
      "player # 2\n",
      "move taken c6b8.m1\n",
      "move {'piece': 2, 'square1': 42, 'square2': 57, 'square3': 64, 'type': 2, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:N   .     .     .     .     .     .   |\n",
      "7|  50:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "3 player # in model\n",
      "player # 3\n",
      "move taken a7b8.m1\n",
      "move {'piece': 14, 'square1': 48, 'square2': 57, 'square3': 64, 'type': 2, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "4 player # in model\n",
      "player # 4\n",
      "move taken h2^g1h1\n",
      "move {'piece': 6, 'square1': 15, 'square2': 6, 'square3': 7, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .     .     .    50:K  50:K |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "5 player # in model\n",
      "player # 5\n",
      "move taken b8c8\n",
      "move {'piece': 14, 'square1': 57, 'square2': 58, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .   100:k   .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .     .     .    50:K  50:K |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "6 player # in model\n",
      "player # 6\n",
      "move taken b7c8N.m1\n",
      "move {'piece': 1, 'square1': 49, 'square2': 58, 'square3': 64, 'type': 10, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 2}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .   100:N   .     .     .     .     .   |\n",
      "7|   .     .     .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .     .     .    50:K  50:K |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "game 1 finished\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0271]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.9935]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.7614]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.6566]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.2477]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "6\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.1884]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "1\n",
      "0 player # in model\n",
      "hit time limit\n",
      "player # 0\n",
      "move taken b1^b6e1\n",
      "move {'piece': 4, 'square1': 1, 'square2': 41, 'square3': 4, 'type': 5, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7| 100:k   .   100:K   .     .     .     .     .   |\n",
      "6|   .    50:R   .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .    50:R   .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "1 player # in model\n",
      "player # 1\n",
      "move taken a7b6.m1\n",
      "move {'piece': 14, 'square1': 48, 'square2': 41, 'square3': 64, 'type': 2, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .     .   100:K   .     .     .     .     .   |\n",
      "6|   .   100:k   .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .    50:R   .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "2 player # in model\n",
      "player # 2\n",
      "move taken c7b6.m1\n",
      "move {'piece': 6, 'square1': 50, 'square2': 41, 'square3': 64, 'type': 2, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .     .     .     .     .     .     .     .   |\n",
      "6|   .   100:K   .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .    50:R   .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "game 2 finished\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.2741]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0743]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "4\n",
      "1 player # in model\n",
      "player # 1\n",
      "move taken a8b8\n",
      "move {'piece': 14, 'square1': 56, 'square2': 57, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .   100:N   .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "2 player # in model\n",
      "player # 2\n",
      "move taken c6e7\n",
      "move {'piece': 2, 'square1': 42, 'square2': 52, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .   100:N   .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "3 player # in model\n",
      "player # 3\n",
      "move taken b8^a8a7\n",
      "move {'piece': 14, 'square1': 57, 'square2': 56, 'square3': 48, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|  50:k   .     .     .     .     .     .     .   |\n",
      "7|  50:k 100:P   .     .   100:N   .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "4 player # in model\n",
      "player # 4\n",
      "move taken e7^c8c6\n",
      "move {'piece': 2, 'square1': 52, 'square2': 58, 'square3': 42, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|  50:k   .    50:N   .     .     .     .     .   |\n",
      "7|  50:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .    50:N   .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "5 player # in model\n",
      "player # 5\n",
      "move taken a7a8^b8\n",
      "move {'piece': 14, 'square1': 48, 'square2': 56, 'square3': 57, 'type': 6, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k  50:N   .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .    50:N   .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "6 player # in model\n",
      "player # 6\n",
      "move taken c6e7\n",
      "move {'piece': 2, 'square1': 42, 'square2': 52, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:k  50:N   .     .     .     .     .   |\n",
      "7|   .   100:P   .     .    50:N   .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "7 player # in model\n",
      "player # 7\n",
      "move taken b8a7\n",
      "move {'piece': 14, 'square1': 57, 'square2': 48, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .    50:N   .     .     .     .     .   |\n",
      "7| 100:k 100:P   .     .    50:N   .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "8 player # in model\n",
      "player # 8\n",
      "move taken e7f5\n",
      "move {'piece': 2, 'square1': 52, 'square2': 37, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .    50:N   .     .     .     .     .   |\n",
      "7| 100:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .    50:N   .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "9 player # in model\n",
      "game 3 finished\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.4526]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.2428]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0098]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.1298]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.1340]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0726]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0225]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0576]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "0 player # in model\n",
      "player # 0\n",
      "move taken f1g1\n",
      "move {'piece': 6, 'square1': 5, 'square2': 6, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .     .     .     .     .     .     .     .   |\n",
      "6|   .     .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .   100:k   .     .   |\n",
      "2|   .     .     .     .     .   100:p   .     .   |\n",
      "1|   .     .     .     .     .     .   100:K   .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "1 player # in model\n",
      "player # 1\n",
      "move taken f2g1r.m1\n",
      "move {'piece': 9, 'square1': 13, 'square2': 6, 'square3': 64, 'type': 10, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 1, 'promotion_piece': 12}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .     .     .     .     .     .     .     .   |\n",
      "6|   .     .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .   100:k   .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .     .     .   100:r   .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "game 4 finished\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0231]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "9\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0190]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "6\n",
      "1 player # in model\n",
      "player # 1\n",
      "move taken a8a7\n",
      "move {'piece': 14, 'square1': 56, 'square2': 48, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7| 100:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .   100:N   .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "2 player # in model\n",
      "player # 2\n",
      "move taken c6^e7b8\n",
      "move {'piece': 2, 'square1': 42, 'square2': 52, 'square3': 57, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .    50:N   .     .     .     .     .     .   |\n",
      "7| 100:k 100:P   .     .    50:N   .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "3 player # in model\n",
      "player # 3\n",
      "move taken a7b6\n",
      "move {'piece': 14, 'square1': 48, 'square2': 41, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .    50:N   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .    50:N   .     .     .   |\n",
      "6| 100:P 100:k   .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "4 player # in model\n",
      "player # 4\n",
      "move taken b7b8R.m0\n",
      "move {'piece': 1, 'square1': 49, 'square2': 57, 'square3': 64, 'type': 2, 'variant': 2, 'does_measurement': True, 'measurement_outcome': 0, 'promotion_piece': 4}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:N   .     .     .     .     .     .   |\n",
      "7|   .   100:P   .     .     .     .     .     .   |\n",
      "6| 100:P 100:k   .     .     .     .     .     .   |\n",
      "5|   .     .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "5 player # in model\n",
      "player # 5\n",
      "move taken b6^a7a5\n",
      "move {'piece': 14, 'square1': 41, 'square2': 48, 'square3': 32, 'type': 4, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .   100:N   .     .     .     .     .     .   |\n",
      "7|  50:k 100:P   .     .     .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|  50:k   .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "6 player # in model\n",
      "player # 6\n",
      "move taken b8d7\n",
      "move {'piece': 2, 'square1': 57, 'square2': 51, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|  50:k 100:P   .   100:N   .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5|  50:k   .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "7 player # in model\n",
      "player # 7\n",
      "move taken a7b7.m0\n",
      "move {'piece': 14, 'square1': 48, 'square2': 49, 'square3': 64, 'type': 2, 'variant': 3, 'does_measurement': True, 'measurement_outcome': 0, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .   100:P   .   100:N   .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5| 100:k   .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .   100:K |\n",
      "1|   .     .     .     .     .     .     .     .   |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "8 player # in model\n",
      "player # 8\n",
      "move taken h2h1\n",
      "move {'piece': 6, 'square1': 15, 'square2': 7, 'square3': 64, 'type': 2, 'variant': 1, 'does_measurement': False, 'measurement_outcome': 1, 'promotion_piece': 0}\n",
      " +-------------------------------------------------+\n",
      "8|   .     .     .     .     .     .     .     .   |\n",
      "7|   .   100:P   .   100:N   .     .     .     .   |\n",
      "6| 100:P   .     .     .     .     .     .     .   |\n",
      "5| 100:k   .     .     .     .     .     .     .   |\n",
      "4|   .     .     .     .     .     .     .     .   |\n",
      "3|   .     .     .     .     .     .     .     .   |\n",
      "2|   .     .     .     .     .     .     .     .   |\n",
      "1|   .     .     .     .     .     .     .   100:K |\n",
      " +-------------------------------------------------+\n",
      "     a     b     c     d     e     f     g     h\n",
      "9 player # in model\n",
      "game 5 finished\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0913]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0846]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0696]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0511]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "14\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0299]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0084]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "1\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[-0.0120]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "2\n",
      "predicted value:  {<class 'torch.Tensor'>} true value:  {<class 'torch.Tensor'>}\n",
      "tensor([[0.0369]], grad_fn=<TanhBackward0>)\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "6\n",
      "0 player # in model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m         model_scripted\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestExport.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m train_model(NNmodel, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(NNmodel, player1bot, player2bot, games_per_epoch, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m game \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(games_per_epoch):\n\u001b[1;32m---> 10\u001b[0m     board_data_w, board_data_b, moves_W, moves_B, values_W, values_B, result \u001b[38;5;241m=\u001b[39m self_play_game(NNmodel, \u001b[38;5;241m9\u001b[39m, player1bot, player2bot)  \u001b[38;5;66;03m# Play a game\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Train the model on the collected game data\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m, in \u001b[0;36mself_play_game\u001b[1;34m(model, moveMax, player1bot, player2bot)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (gamedata\u001b[38;5;241m.\u001b[39mply \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(player1bot):\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m#best_move, value = MCTSAI.find_best_move(game, 50)\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m         best_move, value \u001b[38;5;241m=\u001b[39m mcts_nn\u001b[38;5;241m.\u001b[39mfind_best_move(game, model, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m         best_move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your move: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mNetworkMCTS.find_best_move\u001b[1;34m(self, game, model, simVar)\u001b[0m\n\u001b[0;32m      7\u001b[0m root \u001b[38;5;241m=\u001b[39m MCTS_NN\u001b[38;5;241m.\u001b[39mMCTS_Node(game, model)\n\u001b[0;32m      8\u001b[0m gamedata \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_game_data()\n\u001b[1;32m----> 9\u001b[0m bestmove, value \u001b[38;5;241m=\u001b[39m root\u001b[38;5;241m.\u001b[39mbest_action(gamedata\u001b[38;5;241m.\u001b[39mply, model, simVar)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bestmove, value\n",
      "File \u001b[1;32mc:\\Code\\Quantum-Chess-AI-Development\\MCTS_NN.py:171\u001b[0m, in \u001b[0;36mMCTS_Node.best_action\u001b[1;34m(self, player, model, simVar, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m simulation_no \u001b[38;5;241m=\u001b[39m simVar\u001b[38;5;241m*\u001b[39ml \u001b[38;5;66;03m#adaptive simulations\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(simulation_no):\n\u001b[1;32m--> 171\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree_policy()\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m#print(f\"node reached: {v.parent_action}, terminal: {v.is_terminal_node()}\") #debug\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Code\\Quantum-Chess-AI-Development\\MCTS_NN.py:150\u001b[0m, in \u001b[0;36mMCTS_Node._tree_policy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m current_node\u001b[38;5;241m.\u001b[39mexpand()\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m         current_node \u001b[38;5;241m=\u001b[39m current_node\u001b[38;5;241m.\u001b[39mbest_child()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#print(f\"Terminal node reached: {current_node.parent_action}\")\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m current_node\n",
      "File \u001b[1;32mc:\\Code\\Quantum-Chess-AI-Development\\MCTS_NN.py:127\u001b[0m, in \u001b[0;36mMCTS_Node.best_child\u001b[1;34m(self, c_param)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_child\u001b[39m(\u001b[38;5;28mself\u001b[39m, c_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m#classic MCTS equation, c_param could probably be tweaked a bit\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     choices_weights \u001b[38;5;241m=\u001b[39m [(np\u001b[38;5;241m.\u001b[39mmultiply(c\u001b[38;5;241m.\u001b[39mnn_rating(), \u001b[38;5;241m0.2\u001b[39m)) \u001b[38;5;241m+\u001b[39m (c\u001b[38;5;241m.\u001b[39mq() \u001b[38;5;241m/\u001b[39m c\u001b[38;5;241m.\u001b[39mn()) \u001b[38;5;241m+\u001b[39m c_param \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn()) \u001b[38;5;241m/\u001b[39m c\u001b[38;5;241m.\u001b[39mn())) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren] \n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren[np\u001b[38;5;241m.\u001b[39margmax(choices_weights)]\n",
      "File \u001b[1;32mc:\\Code\\Quantum-Chess-AI-Development\\MCTS_NN.py:63\u001b[0m, in \u001b[0;36mMCTS_Node.nn_rating\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     61\u001b[0m tensor[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m gameToTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_state\u001b[38;5;241m.\u001b[39mget_game_data(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_state\u001b[38;5;241m.\u001b[39mget_game_data()\u001b[38;5;241m.\u001b[39mply)\n\u001b[1;32m---> 63\u001b[0m NNrating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNNmodel(tensor)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NNrating,\n",
      "File \u001b[1;32mc:\\Users\\torin\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\torin\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Code\\Quantum-Chess-AI-Development\\QChessNN.py:44\u001b[0m, in \u001b[0;36mQChessNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n\u001b[0;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Value Head\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\torin\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "def train_model(NNmodel, player1bot, player2bot, games_per_epoch, epochs):\n",
    "    optimizer = torch.optim.Adam(NNmodel.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    game_tensor = torch.zeros(1,12,8,8)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"starting epoch {epoch + 1}\")\n",
    "        for game in range(games_per_epoch):\n",
    "            \n",
    "            \n",
    "            board_data_w, board_data_b, moves_W, moves_B, values_W, values_B, result = self_play_game(NNmodel, 9, player1bot, player2bot)  # Play a game\n",
    "            print(f\"game {game + 1} finished\")\n",
    "            # Train the model on the collected game data\n",
    "            \n",
    "            for i in range(len(moves_B)):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                game_tensor[0] = gameToTensor(board_data_b[i], 1)\n",
    "\n",
    "                predicted_value = NNmodel(game_tensor)\n",
    "                true_value = torch.tensor([[values_B[i]]], dtype=torch.float32)\n",
    "\n",
    "                print(f\"predicted value: \", {type(predicted_value[0])}, \"true value: \", {type(true_value)})\n",
    "                value_loss = F.mse_loss(predicted_value[0], true_value)\n",
    "                \n",
    "\n",
    "                print(predicted_value[0])\n",
    "\n",
    "                piece = predicted_value[1][0]\n",
    "                pos1 = predicted_value[1][1]\n",
    "                pos2 = predicted_value[1][2]\n",
    "                pos3 = predicted_value[1][3]\n",
    "                move_type = predicted_value[1][4]\n",
    "                variation = predicted_value[1][5]\n",
    "                print(piece)\n",
    "                print(moves_B[i]['piece'])\n",
    "                # Assuming you have the true labels for the policy head\n",
    "                true_piece = torch.tensor([[round(moves_B[i]['piece'])]], dtype=torch.float)  # Replace with actual label\n",
    "                true_pos1 = torch.tensor([[round(moves_B[i]['square1'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_pos2 = torch.tensor([[round(moves_B[i]['square2'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_pos3 = torch.tensor([[round(moves_B[i]['square3'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_move_type = torch.tensor([[round(moves_B[i]['type'])]], dtype=torch.float)  # Replace with actual label\n",
    "                true_variation = torch.tensor([[round(moves_B[i]['variant'])]], dtype=torch.float)  # Replace with actual label\n",
    "\n",
    "                # Compute policy loss\n",
    "                policy_loss = (\n",
    "                    F.cross_entropy(piece, true_piece) +\n",
    "                    F.cross_entropy(pos1, true_pos1) +\n",
    "                    F.cross_entropy(pos2, true_pos2) +\n",
    "                    F.cross_entropy(pos3, true_pos3) +\n",
    "                    F.cross_entropy(move_type, true_move_type) +\n",
    "                    F.cross_entropy(variation, true_variation)\n",
    "                )\n",
    "                \n",
    "                # Combine value loss and policy loss\n",
    "                total_loss = value_loss + policy_loss\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            \n",
    "            for i in range(len(moves_B)):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                game_tensor[0] = gameToTensor(board_data_w[i], 1)\n",
    "\n",
    "                predicted_value = NNmodel(game_tensor)\n",
    "                true_value = torch.tensor([[values_W[i]]], dtype=torch.float32)\n",
    "\n",
    "                print(f\"predicted value: \", {type(predicted_value[0])}, \"true value: \", {type(true_value)})\n",
    "                value_loss = F.mse_loss(predicted_value[0], true_value)\n",
    "                \n",
    "\n",
    "                print(predicted_value[0])\n",
    "\n",
    "                piece = predicted_value[1][0]\n",
    "                pos1 = predicted_value[1][1]\n",
    "                pos2 = predicted_value[1][2]\n",
    "                pos3 = predicted_value[1][3]\n",
    "                move_type = predicted_value[1][4]\n",
    "                variation = predicted_value[1][5]\n",
    "                print(piece)\n",
    "                print(moves_W[i]['piece'])\n",
    "                # Assuming you have the true labels for the policy head\n",
    "                true_piece = torch.tensor([[round(moves_W[i]['piece'])]], dtype=torch.float)  # Replace with actual label\n",
    "                true_pos1 = torch.tensor([[round(moves_W[i]['square1'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_pos2 = torch.tensor([[round(moves_W[i]['square2'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_pos3 = torch.tensor([[round(moves_W[i]['square3'])]], dtype=torch.float)   # Replace with actual label\n",
    "                true_move_type = torch.tensor([[round(moves_W[i]['type'])]], dtype=torch.float)  # Replace with actual label\n",
    "                true_variation = torch.tensor([[round(moves_W[i]['variant'])]], dtype=torch.float)  # Replace with actual label\n",
    "\n",
    "                # Compute policy loss\n",
    "                policy_loss = (\n",
    "                    F.cross_entropy(piece, true_piece) +\n",
    "                    F.cross_entropy(pos1, true_pos1) +\n",
    "                    F.cross_entropy(pos2, true_pos2) +\n",
    "                    F.cross_entropy(pos3, true_pos3) +\n",
    "                    F.cross_entropy(move_type, true_move_type) +\n",
    "                    F.cross_entropy(variation, true_variation)\n",
    "                )\n",
    "                \n",
    "                # Combine value loss and policy loss\n",
    "                total_loss = value_loss + policy_loss\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        print(f\"epoch {epoch + 1} finished\")\n",
    "        model_scripted = torch.jit.script(NNmodel) # Export to TorchScript\n",
    "        model_scripted.save('testExport.pt') # Save\n",
    "    print(\"Training finished\")\n",
    "    \n",
    "train_model(NNmodel, True, True, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31240686-57e0-4efb-a34b-22a4714ae2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = QuantumChessGame()\n",
    "game.new_game({'initial_state_fen':get_puzzle_fen(33),  'max_split_moves':[0,1]});\n",
    "game_tensor[0] = gameToTensor(game.get_game_data(), 0)\n",
    "\n",
    "output = NNmodel(game_tensor)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
